{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7cfbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# from tensorflow import keras\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "# from tensorflow.keras.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "mpl.rcParams['figure.figsize'] = (15,15)\n",
    "mpl.rcParams['axes.grid'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ba7278",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Aqi_new.csv')\n",
    "new = pd.read_csv('mumbai-us consulate-air-quality.csv')\n",
    "new.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0896d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new['From Date'] = pd.to_datetime(new['From Date'],infer_datetime_format=True)\n",
    "new['AQI_calculated'] = new['AQI_calculated'].astype(float)\n",
    "new.set_index('From Date', inplace=True)\n",
    "new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14529ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d2260a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['From Date'] = pd.to_datetime(df['From Date'],infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fe913a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace('None', np.nan)\n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f36f01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy()\n",
    "df1.drop(['From Date','To Date','Station'], axis = 'columns', inplace=True)\n",
    "df1.head()\n",
    "df1 = df1.astype(float)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83ccbfa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.drop(['To Date'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18445b7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_PM25_subindex(x):\n",
    "    if x <= 30:\n",
    "        return x * 50 / 30\n",
    "    elif x <= 60:\n",
    "        return 50 + (x - 30) * 50 / 30\n",
    "    elif x <= 90:\n",
    "        return 100 + (x - 60) * 100 / 30\n",
    "    elif x <= 120:\n",
    "        return 200 + (x - 90) * 100 / 30\n",
    "    elif x <= 250:\n",
    "        return 300 + (x - 120) * 100 / 130\n",
    "    elif x > 250:\n",
    "        return 400 + (x - 250) * 100 / 130\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "df1[\"PM2.5_SubIndex\"] = df1['PM2.5'].apply(lambda x: get_PM25_subindex(x))\n",
    "\n",
    "## PM10 Sub-Index calculation\n",
    "def get_PM10_subindex(x):\n",
    "    if x <= 50:\n",
    "        return x\n",
    "    elif x <= 100:\n",
    "        return x\n",
    "    elif x <= 250:\n",
    "        return 100 + (x - 100) * 100 / 150\n",
    "    elif x <= 350:\n",
    "        return 200 + (x - 250)\n",
    "    elif x <= 430:\n",
    "        return 300 + (x - 350) * 100 / 80\n",
    "    elif x > 430:\n",
    "        return 400 + (x - 430) * 100 / 80\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "df1[\"PM10_SubIndex\"] = df1[\"PM10\"].apply(lambda x: get_PM10_subindex(x))\n",
    "\n",
    "## SO2 Sub-Index calculation\n",
    "def get_SO2_subindex(x):\n",
    "    if x <= 40:\n",
    "        return x * 50 / 40\n",
    "    elif x <= 80:\n",
    "        return 50 + (x - 40) * 50 / 40\n",
    "    elif x <= 380:\n",
    "        return 100 + (x - 80) * 100 / 300\n",
    "    elif x <= 800:\n",
    "        return 200 + (x - 380) * 100 / 420\n",
    "    elif x <= 1600:\n",
    "        return 300 + (x - 800) * 100 / 800\n",
    "    elif x > 1600:\n",
    "        return 400 + (x - 1600) * 100 / 800\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "df1[\"SO2_SubIndex\"] = df1[\"SO2\"].apply(lambda x: get_SO2_subindex(x))\n",
    "\n",
    "## NOx Sub-Index calculation\n",
    "def get_NOx_subindex(x):\n",
    "    if x <= 40:\n",
    "        return x * 50 / 40\n",
    "    elif x <= 80:\n",
    "        return 50 + (x - 40) * 50 / 40\n",
    "    elif x <= 180:\n",
    "        return 100 + (x - 80) * 100 / 100\n",
    "    elif x <= 280:\n",
    "        return 200 + (x - 180) * 100 / 100\n",
    "    elif x <= 400:\n",
    "        return 300 + (x - 280) * 100 / 120\n",
    "    elif x > 400:\n",
    "        return 400 + (x - 400) * 100 / 120\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "df1[\"NOx_SubIndex\"] = df1[\"NOx\"].apply(lambda x: get_NOx_subindex(x))\n",
    "\n",
    "## CO Sub-Index calculation\n",
    "def get_CO_subindex(x):\n",
    "    if x <= 1:\n",
    "        return x * 50 / 1\n",
    "    elif x <= 2:\n",
    "        return 50 + (x - 1) * 50 / 1\n",
    "    elif x <= 10:\n",
    "        return 100 + (x - 2) * 100 / 8\n",
    "    elif x <= 17:\n",
    "        return 200 + (x - 10) * 100 / 7\n",
    "    elif x <= 34:\n",
    "        return 300 + (x - 17) * 100 / 17\n",
    "    elif x > 34:\n",
    "        return 400 + (x - 34) * 100 / 17\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "df1[\"CO_SubIndex\"] = df1[\"CO\"].apply(lambda x: get_CO_subindex(x))\n",
    "\n",
    "## O3 Sub-Index calculation\n",
    "def get_O3_subindex(x):\n",
    "    if x <= 50:\n",
    "        return x * 50 / 50\n",
    "    elif x <= 100:\n",
    "        return 50 + (x - 50) * 50 / 50\n",
    "    elif x <= 168:\n",
    "        return 100 + (x - 100) * 100 / 68\n",
    "    elif x <= 208:\n",
    "        return 200 + (x - 168) * 100 / 40\n",
    "    elif x <= 748:\n",
    "        return 300 + (x - 208) * 100 / 539\n",
    "    elif x > 748:\n",
    "        return 400 + (x - 400) * 100 / 539\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "df1[\"Ozone_SubIndex\"] = df1[\"Ozone\"].apply(lambda x: get_O3_subindex(x))\n",
    "\n",
    "## NH3 Sub-Index calculation\n",
    "def get_NH3_subindex(x):\n",
    "    if x <= 30:\n",
    "        return x * 50 / 30\n",
    "    elif x <= 60:\n",
    "        return 50 + (x - 30) * 50 / 30\n",
    "    elif x <= 90:\n",
    "        return 100 + (x - 60) * 100 / 30\n",
    "    elif x <= 120:\n",
    "        return 200 + (x - 90) * 100 / 30\n",
    "    elif x <= 250:\n",
    "        return 300 + (x - 120) * 100 / 130\n",
    "    elif x > 250:\n",
    "        return 400 + (x - 250) * 100 / 130\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "df1[\"NH3_SubIndex\"] = df1['NH3'].apply(lambda x: get_PM25_subindex(x))\n",
    "\n",
    "## AQI bucketing\n",
    "def get_AQI_bucket(x):\n",
    "    if x <= 50:\n",
    "        return \"Good\"\n",
    "    elif x <= 100:\n",
    "        return \"Satisfactory\"\n",
    "    elif x <= 200:\n",
    "        return \"Moderate\"\n",
    "    elif x <= 300:\n",
    "        return \"Poor\"\n",
    "    elif x <= 400:\n",
    "        return \"Very Poor\"\n",
    "    elif x > 400:\n",
    "        return \"Severe\"\n",
    "    else:\n",
    "        return np.NaN\n",
    "\n",
    "df1[\"Checks\"] = (df1[\"PM2.5_SubIndex\"] > 0).astype(int) + \\\n",
    "                (df1[\"PM10_SubIndex\"] > 0).astype(int) + \\\n",
    "                (df1[\"SO2_SubIndex\"] > 0).astype(int) + \\\n",
    "                (df1[\"NOx_SubIndex\"] > 0).astype(int) + \\\n",
    "                (df1[\"CO_SubIndex\"] > 0).astype(int) + \\\n",
    "                (df1[\"NH3_SubIndex\"] > 0).astype(int) + \\\n",
    "                (df1[\"Ozone_SubIndex\"] > 0).astype(int)\n",
    "\n",
    "df1[\"AQI_calculated\"] = round(df1[[\"PM2.5_SubIndex\", \"PM10_SubIndex\", \"SO2_SubIndex\", \"NOx_SubIndex\",\n",
    "                                  \"CO_SubIndex\", \"Ozone_SubIndex\",\"NH3_SubIndex\"]].max(axis = 1))\n",
    "\n",
    "df1.loc[df1[\"PM2.5_SubIndex\"] + df1[\"PM10_SubIndex\"] <= 0, \"AQI_calculated\"] = np.NaN\n",
    "df1.loc[df1.Checks < 3, \"AQI_calculated\"] = np.NaN\n",
    "\n",
    "\n",
    "df1[\"AQI_bucket_calculated\"] = df1[\"AQI_calculated\"].apply(lambda x: get_AQI_bucket(x))\n",
    "df1[~df1.AQI_calculated.isna()].head(10)\n",
    "df1.drop(['PM2.5_SubIndex','PM10_SubIndex','SO2_SubIndex','NOx_SubIndex','CO_SubIndex','NH3_SubIndex','Ozone_SubIndex','Checks','AQI_bucket_calculated'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d02718",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df,df1['AQI_calculated']],axis=1)\n",
    "df.drop(['To Date'],axis=1,inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08afd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[['From Date', 'Station']].copy()\n",
    "df.drop(['From Date','Station'],axis=1,inplace=True)\n",
    "df = df.astype(float)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e5afba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df2,df],axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069a9ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean = ['PM2.5','PM10',       \n",
    "#    'NO',           \n",
    "#    'NO2',         \n",
    "#     'NOx',          \n",
    "#     'NH3',        \n",
    "#     'SO2',        \n",
    "#     'CO',       \n",
    "#    'Ozone',   \n",
    "#    'Benzene',   \n",
    "#    'Toluene',    \n",
    "#    'Eth-Benzene', \n",
    "# #         'MP-Xylene',\n",
    "#    'RH',\n",
    "# #     'SR',\n",
    "#    'WS',\n",
    "#    'WD',\n",
    "#    'BP',\n",
    "#    'RF',\n",
    "#    'Xylene',\n",
    "#    'AT',\n",
    "#    'TOT-RF','AQI_calculated']\n",
    "mean = ['AQI_calculated']\n",
    "mean_df = df.groupby('From Date')[mean].mean()\n",
    "# mean_df = mean_df[['AQI_calculated']]\n",
    "mean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a16304b",
   "metadata": {},
   "outputs": [],
   "source": [
    "newww = pd.concat([new, mean_df])\n",
    "dfs = newww.sort_values('From Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3a05b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d671bcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_input = mean_df[['PM2.5','PM10',       \n",
    "#    'NO',           \n",
    "#    'NO2',         \n",
    "#     'NOx',          \n",
    "#     'NH3',        \n",
    "#     'SO2',        \n",
    "#     'CO',       \n",
    "#    'Ozone',   \n",
    "#    'Benzene',   \n",
    "#    'Toluene',    \n",
    "#    'Eth-Benzene', \n",
    "# #         'MP-Xylene',\n",
    "#    'RH',\n",
    "# #     'SR',\n",
    "#    'WS',\n",
    "#    'WD',\n",
    "#    'BP',\n",
    "#    'RF',\n",
    "#    'Xylene',\n",
    "#    'AT',\n",
    "#    'TOT-RF','AQI_calculated']]\n",
    "df_input = dfs[['AQI_calculated']]\n",
    "df_input.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18a6601",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_input.query('AQI_calculated > 400')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9b19d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_input = df_input[df_input['AQI_calculated'] <= 400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acaae75",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "data_scaled = scaler.fit_transform(df_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802ae211",
   "metadata": {},
   "outputs": [],
   "source": [
    "features=data_scaled\n",
    "target=data_scaled[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934fbd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "TimeseriesGenerator(features, target, length=2, sampling_rate=1, batch_size=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3723d856",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(features, target, test_size=0.20, random_state=123, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7fd56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "win_length = 31\n",
    "batch_size = 3\n",
    "num_features = 1\n",
    "# train_generator = TimeseriesGenerator(x_train, y_train, length=win_length, sampling_rate=1, batch_size=batch_size)\n",
    "test_generator = TimeseriesGenerator(x_test, y_test, length=win_length, sampling_rate=1, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44323c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('RNN31_1.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0971440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.Sequential()\n",
    "# model.add(tf.keras.layers.SimpleRNN(128,input_shape = (win_length,num_features),return_sequences = True))\n",
    "# model.add(tf.keras.layers.LeakyReLU(alpha = 0.5))\n",
    "# model.add(tf.keras.layers.SimpleRNN(128,return_sequences = True))\n",
    "# model.add(tf.keras.layers.LeakyReLU(alpha = 0.1))\n",
    "# model.add(tf.keras.layers.Dropout(0.3))\n",
    "# model.add(tf.keras.layers.SimpleRNN(64,return_sequences = False))\n",
    "# model.add(tf.keras.layers.Dropout(0.3))\n",
    "# model.add(tf.keras.layers.Dense(x_train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7b063e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c512b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.losses.MeanSquaredError(),\n",
    "              optimizer=tf.optimizers.Adam(),\n",
    "              metrics=[tf.metrics.MeanAbsoluteError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd385279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "#                                                     patience=2,\n",
    "#                                                     mode='min')\n",
    "\n",
    "# model.compile(loss=tf.losses.MeanSquaredError(),\n",
    "#               optimizer=tf.optimizers.Adam(),\n",
    "#               metrics=[tf.metrics.MeanAbsoluteError()])\n",
    "\n",
    "# history = model.fit_generator(train_generator, epochs=50,\n",
    "#                     validation_data=test_generator,\n",
    "#                     shuffle=False,\n",
    "#                     callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b89f3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions=model.predict(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9f6673",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b784aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred=pd.concat([pd.DataFrame(predictions), pd.DataFrame(x_test[:,1:][win_length:])],axis=1)\n",
    "df_pred\n",
    "# df_pred = pd.DataFrame(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df01b728",
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_trans=scaler.inverse_transform(df_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ba632b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final=df_input[predictions.shape[0]*-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cfa548",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03d2ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['Aqi_Pred']=rev_trans[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456c1a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['Aqi_Pred']=rev_trans[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f3dbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final[['AQI_calculated','Aqi_Pred']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f398b0db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a48c483",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1e347d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
